{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Токенизация в NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NLTK](https://www.nltk.org) - хорошая библиотека, в ней есть много всего - токенизация, лемматизация, обертки под парсеры, метрики, генераторы...\n",
    "\n",
    "Есть и недостатки:\n",
    "* многие инструменты есть только для английского\n",
    "* сомнительного качества документация, иногда приходится лезть в исходный код\n",
    "\n",
    "Тем не менее, NLTK - точно лучше, чем писать велосипеды на костылях руками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "* [документация, где очень много всего и описано много токенизаторов](https://www.nltk.org/api/nltk.tokenize.html)\n",
    "* [исходный код самого общего токенизатора](https://www.nltk.org/_modules/nltk/tokenize.html)\n",
    "* [примеры на два самых общих токенизатора](http://www.nltk.org/howto/tokenize.html)\n",
    "\n",
    "Самая общая вещь, которую можно применить если у вас просто текст (в котором не надо парсить, например, #самыедлинныетэгивмире) - функция `word_tokenize` из `nltk.tokenize`. Она написана для английского и обрабатывает много сложных случаев, для русского - надо смотреть, что нужно для задачи, и, возможно, докручивать.\n",
    "\n",
    "В `word_tokenize` надо подавать строку с предложением. Есть второй параметр - язык, но русского нет, поэтому язык можно не указывать, по умолчанию там стоит английский.\n",
    "\n",
    "## Деление на предложения\n",
    "Еще полезная функция, которую вызывает внутри себя `word_tokenize`, но которой можно также пользоваться - `sent_tokenize`. Эта функция делит текст не на слова, а на предложения. Это называется \"сплиттер\". Пользоваться ей можно так же как `word_tokenize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "`sents` - список предложений с разными сложными случаями. Токенизируйте каждое предложение и выведите результат в каком-нибудь удобно читаемом виде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = [\n",
    "    \"On a $50,000 mortgage of 30 years at 8 percent, the monthly payment would be $366.88.\",\n",
    "    \"\\\"We beat some pretty good teams to get here,\\\" Slocum said.\",\n",
    "    \"Well, we couldn't have this predictable, cliche-ridden, \\\"Touched by an Angel\\\" (a show creator John Masius worked on) wanna-be if she didn't.\",\n",
    "    \"I cannot work under these conditions!!!\",\n",
    "    \"He arrived at 3:00 pm.\",\n",
    "    \"I walked down the Oxford St. and bought cool shoes.\"\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`multi_sents` - это две строки, где содержатся по два предложения. Разбейте их на предложения, а предложения на слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "multi_sents = [\n",
    "    \"Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.\",\n",
    "    \"I called Dr. Jones. I called Dr. Jones.\"\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопросы к обсуждению:\n",
    "1. обработку каких разных случаев вы видите?\n",
    "2. какие, может быть, есть проблемы?\n",
    "\n",
    "### Задание 2.\n",
    "Попробуйте придумать похожие сложные случаи для русского (и в целом) и посмотрите, справляется ли с ними этот токенизатор.<br>\n",
    "(Я знаю несколько моментов, где результат его работы не всегда может считаться корректным. Возможно, вы найдете другие сложности.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Индексы токенов\n",
    "\n",
    "Индексы токенов, если токены уже есть, можно получить с помощью функции `align_tokens`, которая принимает на вход список токенов и исходный текст-строку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (3, 4), (5, 6), (6, 12), (13, 21), (22, 24), (25, 27), (28, 33), (34, 36), (37, 38), (39, 46), (46, 47), (48, 51), (52, 59), (60, 67), (68, 73), (74, 76), (77, 78), (78, 84), (84, 85)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.util import align_tokens\n",
    "\n",
    "s = \"On a $50,000 mortgage of 30 years at 8 percent, the monthly payment would be $366.88.\"\n",
    "tokens = word_tokenize(s)\n",
    "spans = align_tokens(tokens, s)\n",
    "print(spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.\n",
    "Посмотрите, что происходит с предложением с кавычками. Подумайте, как это можно исправить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \"\\\"We beat some pretty good teams to get here,\\\" Slocum said.\"\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лемматизация\n",
    "\n",
    "Наши предложения на сегодня:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = 'ВКС 27 июля обнаружили и уничтожили запущенный с территории боевиков беспилотник, приближавшийся к авиабазе.'\n",
    "unkn_sent = 'Я пофиксил баг в продакшене.' # предложение с незнакомыми словами\n",
    "\n",
    "# омонимия\n",
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [mystem](https://tech.yandex.ru/mystem/)\n",
    "Как запускать:\n",
    "* можно скачать mystem и вызывать его [из командной строки с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* можно исполнять команды из пункта выше через питон (см. модуль `subprocess`)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно.\n",
    "\n",
    "Сегодня мы будем работать с pymystem3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы запустили Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, можно не указывать.\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько моментов:\n",
    "* В Mystem нужно подавать строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "* По возможности Mystem (и любые другие вещи этого рода) нужно инициализировать один раз, потому что инициализация занимает время и память.\n",
    "\n",
    "Можно просто лемматизировать текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ВКС', ' ', '27', ' ', 'июль', ' ', 'обнаруживать', ' ', 'и', ' ', 'уничтожать', ' ', 'запущенный', ' ', 'с', ' ', 'территория', ' ', 'боевик', ' ', 'беспилотник', ', ', 'приближаться', ' ', 'к', ' ', 'авиабаза', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [], 'text': 'ВКС'},\n",
       " {'text': ' '},\n",
       " {'text': '27'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,муж,неод=род,ед', 'lex': 'июль', 'wt': 0.997934103}],\n",
       "  'text': 'июля'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,пе=прош,мн,изъяв,сов',\n",
       "    'lex': 'обнаруживать',\n",
       "    'wt': 1}],\n",
       "  'text': 'обнаружили'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'CONJ=', 'lex': 'и', 'wt': 0.9999770522}], 'text': 'и'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,пе=прош,мн,изъяв,сов', 'lex': 'уничтожать', 'wt': 1}],\n",
       "  'text': 'уничтожили'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)',\n",
       "    'lex': 'запущенный',\n",
       "    'wt': 0.9916251898}],\n",
       "  'text': 'запущенный'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': 'с', 'wt': 0.9999778271}], 'text': 'с'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)',\n",
       "    'lex': 'территория',\n",
       "    'wt': 1}],\n",
       "  'text': 'территории'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,муж,од=(вин,мн|род,мн)',\n",
       "    'lex': 'боевик',\n",
       "    'wt': 0.8623402715}],\n",
       "  'text': 'боевиков'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,муж,од=им,ед',\n",
       "    'lex': 'беспилотник',\n",
       "    'qual': 'bastard',\n",
       "    'wt': 0.4965489805}],\n",
       "  'text': 'беспилотник'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'gr': 'V,нп=(прош,вин,ед,прич,полн,муж,несов,действ,неод|прош,им,ед,прич,полн,муж,несов,действ)',\n",
       "    'lex': 'приближаться',\n",
       "    'wt': 1}],\n",
       "  'text': 'приближавшийся'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': 'к', 'wt': 0.9999551773}], 'text': 'к'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,жен,неод=(пр,ед|дат,ед)',\n",
       "    'lex': 'авиабаза',\n",
       "    'wt': 1}],\n",
       "  'text': 'авиабазе'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание.\n",
    "\n",
    "Попробуйте инициализировать Mystem с разными параметрами и посмотреть, что выходит с морфологическим анализом предложения. Конкретные вопросы:\n",
    "1. Что происходит с дизамбигуацией?\n",
    "2. Как хранится грамматическая информация?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие фичи\n",
    "Незнакомые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'gr': 'SPRO,ед,1-л=им', 'lex': 'я', 'wt': 0.9999716282}],\n",
       "  'text': 'Я'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,несов,пе=прош,ед,изъяв,муж',\n",
       "    'lex': 'пофиксить',\n",
       "    'qual': 'bastard',\n",
       "    'wt': 0.6996285915}],\n",
       "  'text': 'пофиксил'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,гео,муж,неод=(вин,ед|им,ед)',\n",
       "    'lex': 'баг',\n",
       "    'qual': 'bastard',\n",
       "    'wt': 1}],\n",
       "  'text': 'баг'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': 'в', 'wt': 0.9999917746}], 'text': 'в'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,муж,неод=пр,ед',\n",
       "    'lex': 'продакшень',\n",
       "    'qual': 'bastard',\n",
       "    'wt': 0.2241225541}],\n",
       "  'text': 'продакшене'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(unkn_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [pymorphy2](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне (то есть всё организовано через ООП), довольно быстрый и с кучей функций.\n",
    "\n",
    "Как запускать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, тк не понимает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ВКС',\n",
       " '27',\n",
       " 'июля',\n",
       " 'обнаружили',\n",
       " 'и',\n",
       " 'уничтожили',\n",
       " 'запущенный',\n",
       " 'с',\n",
       " 'территории',\n",
       " 'боевиков',\n",
       " 'беспилотник',\n",
       " ',',\n",
       " 'приближавшийся',\n",
       " 'к',\n",
       " 'авиабазе',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='территория', score=0.663522, methods_stack=((DictionaryAnalyzer(), 'территории', 41, 6),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='территория', score=0.216981, methods_stack=((DictionaryAnalyzer(), 'территории', 41, 1),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn plur,accs'), normal_form='территория', score=0.047169, methods_stack=((DictionaryAnalyzer(), 'территории', 41, 10),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn plur,nomn'), normal_form='территория', score=0.037735, methods_stack=((DictionaryAnalyzer(), 'территории', 41, 7),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,datv'), normal_form='территория', score=0.034591, methods_stack=((DictionaryAnalyzer(), 'территории', 41, 2),))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = pymorphy2_analyzer.parse(tokens[8])\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "территория\n",
      "NOUN,inan,femn sing,loct\n",
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "print(analysis[0].normal_form) # лемма\n",
    "print(analysis[0].tag) # тэг\n",
    "print(analysis[0].tag.POS) # часть речи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание.\n",
    "Напишите лемматизацию предложения `sent` через pymorphy2. На выходе должен быть массив лемм.\n",
    "Сравните лемматизацию с предложенной mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Незнакомые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('я',\n",
       "  OpencorporaTag('NPRO,1per sing,nomn'),\n",
       "  ((DictionaryAnalyzer(), 'я', 3152, 0),)),\n",
       " ('пофиксила',\n",
       "  OpencorporaTag('NOUN,inan,femn plur,gent'),\n",
       "  ((DictionaryAnalyzer(), 'сил', 55, 8),\n",
       "   (UnknownPrefixAnalyzer(score_multiplier=0.5), 'пофик'))),\n",
       " ('баг',\n",
       "  OpencorporaTag('NOUN,inan,masc sing,accs'),\n",
       "  ((DictionaryAnalyzer(), 'баг', 19, 3),)),\n",
       " ('в', OpencorporaTag('PREP'), ((DictionaryAnalyzer(), 'в', 378, 0),)),\n",
       " ('продакшен',\n",
       "  OpencorporaTag('NOUN,inan,masc,Geox sing,loct'),\n",
       "  ((FakeDictionary(), 'продакшене', 33, 5),\n",
       "   (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'шене'))),\n",
       " ('.', OpencorporaTag('PNCT'), ((PunctuationAnalyzer(score=0.9), '.'),))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = []\n",
    "for token in word_tokenize(unkn_sent):\n",
    "    ana = pymorphy2_analyzer.parse(token)[0]\n",
    "    lemmata.append((ana.normal_form, ana.tag, ana.methods_stack))\n",
    "lemmata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Склонение слов и согласование слов с числительными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inflection: территорию\n",
      "locative + 1: территории\n",
      "locative + 3: территориях\n",
      "locative + 5: территориях\n",
      "nominative + 1: территория\n",
      "nominative + 3: территории\n",
      "nominative + 5: территорий\n"
     ]
    }
   ],
   "source": [
    "loc_analysis = analysis[0]\n",
    "print('inflection:', loc_analysis.inflect({'accs'}).word)\n",
    "print('locative + 1:', loc_analysis.make_agree_with_number(1).word)\n",
    "print('locative + 3:', loc_analysis.make_agree_with_number(3).word)\n",
    "print('locative + 5:', loc_analysis.make_agree_with_number(5).word)\n",
    "\n",
    "nom_analysis = loc_analysis.inflect({'nomn'})\n",
    "print('nominative + 1:',nom_analysis.make_agree_with_number(1).word)\n",
    "print('nominative + 3:',nom_analysis.make_agree_with_number(3).word)\n",
    "print('nominative + 5:',nom_analysis.make_agree_with_number(5).word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Снятие омонимии\n",
    "mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'сорока', 'analysis': [{'lex': 'сорок', 'gr': 'NUM=(пр|дат|род|твор)', 'wt': 0.8710292578}]}\n",
      "{'text': 'Сорока', 'analysis': [{'lex': 'сорока', 'gr': 'S,жен,од=им,ед', 'wt': 0.1210970059}]}\n"
     ]
    }
   ],
   "source": [
    "mystem_analyzer = Mystem() # инициализирую объект снова, потому что было задание на разные параметры, я хочу дефолтные\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Parse(word='сорока', tag=OpencorporaTag('NUMR gent'), normal_form='сорок', score=0.636363, methods_stack=((DictionaryAnalyzer(), 'сорока', 2856, 1),))\n"
     ]
    }
   ],
   "source": [
    "ana1 = pymorphy2_analyzer.parse(homonym1.split(' ')[-2])\n",
    "ana2 = pymorphy2_analyzer.parse(homonym2.split(' ')[0])\n",
    "print(ana1 == ana2)\n",
    "print(ana1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стоп-слова\n",
    "Списки стоп-слов для русского есть разные, можно погуглить, а можно взять из nltk. Может быть, вы посчитаете нужным что-то в него добавить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Знаки препинания\n",
    "Списки знаков препинания тоже уже есть в питоне. Но этот список тоже может понадобиться пополнить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "## Задание 1.\n",
    "Напишите функцию, предобрабатывающую текст. Она вам пригодится для проекта. В предобработку входит:\n",
    "* токенизация\n",
    "* лемматизация\n",
    "* lowercase\n",
    "* удаление знаков препинания и стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    \"\"\"\n",
    "    Processes input text for further use.\n",
    "    :param text: str: input text.\n",
    "    :return: list[str]: lemmata list\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 2.\n",
    "Реализуйте подсчет расстояния Левенштейна. Цена замены - 1.\n",
    "\n",
    "1. Выведите число - расстояние.\n",
    "  * CONNECT -> CONEHEAD: 4\n",
    "  * ПРИМЕРЫ -> ПРЕДМЕТ: 4\n",
    "2. Выведите все необходимые операции, чтобы превратить s1 в s2.  D (англ. delete) — удалить, I (англ. insert) — вставить, R (replace) — заменить, M (match) — совпадение.\n",
    "  * CONNECT -> CONEHEAD: MMMRIMRR\n",
    "  * ПРИМЕРЫ -> ПРЕДМЕТ: MMIRMMRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"\n",
    "    Computes Levenshtein distance between s1 and s2.\n",
    "    :return: int: Levenshtein distance. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "\n",
    "def levenshtein_distance_description(s1, s2):\n",
    "    \"\"\"\n",
    "    Computes Levenshtein edit path between s1 and s2.\n",
    "    :return: str: edit path.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 3.\n",
    "Преобразуйте текст в таблицу, где для каждого слова содержится информация по нему: токен, лемма, часть речи (для знаков препинания - PNCT), индексы начала и конца токена в предложении. Например:\n",
    "\n",
    "```\n",
    "Коля сдал экзамен, потому что хорошо подготовился.\n",
    "\n",
    "Коля\tколя\tNOUN\t0\t4\n",
    "сдал\tсдать\tVERB\t5\t9\n",
    "экзамен\tэкзамен\tNOUN\t10\t17\n",
    ",\t,\tPNCT\t17\t18\n",
    "потому\tпотому\tADVB\t19\t25\n",
    "что\tчто\tCONJ\t26\t29\n",
    "хорошо\tхорошо\tADVB\t30\t36\n",
    "подготовился\tподготовиться\tVERB\t37\t49\n",
    ".\t.\tPNCT\t49\t50\n",
    "```\n",
    "\n",
    "В функцию должно быть можно передать аргумент, какой использовать анализатор - `pymorphy2` или `mystem`. Запишите таблицу в csv-файл. csv (comma-separated values) - это формат, в котором в каждой строке записана строка таблицы, а ячейки в строке разделены каким-либо разделителем (запятая, точка с запятой, табуляция (тогда это называется tsv))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grammar_table(text, analyzer='pymorphy2'):\n",
    "    \"\"\"\n",
    "    Writes csv with grammar information for given text.\n",
    "    :param text: str: input text.\n",
    "    :param analyzer: str: analyzer to use: 'pymorphy2' or 'mystem' \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
