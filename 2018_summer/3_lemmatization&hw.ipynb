{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лемматизация\n",
    "\n",
    "Наши предложения на сегодня:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = 'ВКС 27 июля обнаружили и уничтожили запущенный с территории боевиков беспилотник, приближавшийся к авиабазе.'\n",
    "unkn_sent = 'Я пофиксил баг в продакшене.' # предложение с незнакомыми словами\n",
    "\n",
    "# омонимия\n",
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [mystem](https://tech.yandex.ru/mystem/)\n",
    "Как запускать:\n",
    "* можно скачать mystem и вызывать его [из командной строки с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* можно исполнять команды из пункта выше через питон (см. модуль `subprocess`)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно.\n",
    "\n",
    "Сегодня мы будем работать с pymystem3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы запустили Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, можно не указывать.\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько моментов:\n",
    "* В Mystem нужно подавать строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "* По возможности Mystem (и любые другие вещи этого рода) нужно инициализировать один раз, потому что инициализация занимает время и память.\n",
    "\n",
    "Можно просто лемматизировать текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ВКС', ' ', '27', ' ', 'июль', ' ', 'обнаруживать', ' ', 'и', ' ', 'уничтожать', ' ', 'запущенный', ' ', 'с', ' ', 'территория', ' ', 'боевик', ' ', 'беспилотник', ', ', 'приближаться', ' ', 'к', ' ', 'авиабаза', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [], 'text': 'ВКС'},\n",
       " {'text': ' '},\n",
       " {'text': '27'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,муж,неод=род,ед', 'lex': 'июль'}], 'text': 'июля'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,пе=прош,мн,изъяв,сов', 'lex': 'обнаруживать'}],\n",
       "  'text': 'обнаружили'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'CONJ=', 'lex': 'и'}], 'text': 'и'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,пе=прош,мн,изъяв,сов', 'lex': 'уничтожать'}],\n",
       "  'text': 'уничтожили'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)',\n",
       "    'lex': 'запущенный'}],\n",
       "  'text': 'запущенный'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': 'с'}], 'text': 'с'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)',\n",
       "    'lex': 'территория'}],\n",
       "  'text': 'территории'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,муж,од=(вин,мн|род,мн)', 'lex': 'боевик'}],\n",
       "  'text': 'боевиков'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,муж,од=им,ед',\n",
       "    'lex': 'беспилотник',\n",
       "    'qual': 'bastard'}],\n",
       "  'text': 'беспилотник'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'gr': 'V,нп=(прош,вин,ед,прич,полн,муж,несов,действ,неод|прош,им,ед,прич,полн,муж,несов,действ)',\n",
       "    'lex': 'приближаться'}],\n",
       "  'text': 'приближавшийся'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': 'к'}], 'text': 'к'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,жен,неод=(пр,ед|дат,ед)', 'lex': 'авиабаза'}],\n",
       "  'text': 'авиабазе'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание.\n",
    "\n",
    "Попробуйте инициализировать Mystem с разными параметрами и посмотреть, что выходит с морфологическим анализом предложения. Конкретные вопросы:\n",
    "1. Что происходит с дизамбигуацией?\n",
    "2. Как хранится грамматическая информация?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие фичи\n",
    "Незнакомые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'gr': 'SPRO,ед,1-л=им', 'lex': 'я'}], 'text': 'Я'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,несов,пе=прош,ед,изъяв,муж',\n",
       "    'lex': 'пофиксить',\n",
       "    'qual': 'bastard'}],\n",
       "  'text': 'пофиксил'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,гео,муж,неод=(вин,ед|им,ед)',\n",
       "    'lex': 'баг',\n",
       "    'qual': 'bastard'}],\n",
       "  'text': 'баг'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': 'в'}], 'text': 'в'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,муж,неод=пр,ед',\n",
       "    'lex': 'продакшень',\n",
       "    'qual': 'bastard'}],\n",
       "  'text': 'продакшене'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(unkn_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [pymorphy2](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне (то есть всё организовано через ООП), довольно быстрый и с кучей функций.\n",
    "\n",
    "Как запускать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, тк не понимает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ВКС',\n",
       " '27',\n",
       " 'июля',\n",
       " 'обнаружили',\n",
       " 'и',\n",
       " 'уничтожили',\n",
       " 'запущенный',\n",
       " 'с',\n",
       " 'территории',\n",
       " 'боевиков',\n",
       " 'беспилотник',\n",
       " ',',\n",
       " 'приближавшийся',\n",
       " 'к',\n",
       " 'авиабазе',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='территория', score=0.714285, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 6),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='территория', score=0.095238, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 1),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,datv'), normal_form='территория', score=0.095238, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 2),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn plur,nomn'), normal_form='территория', score=0.047619, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 7),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn plur,accs'), normal_form='территория', score=0.047619, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 10),))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terra = pymorphy2_analyzer.parse(tokens[8])\n",
    "terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "территория\n",
      "NOUN,inan,femn sing,loct\n",
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "print(terra[0].normal_form) # лемма\n",
    "print(terra[0].tag) # тэг\n",
    "print(terra[0].tag.POS) # часть речи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание.\n",
    "Напишите лемматизацию предложения `sent` через pymorphy2. На выходе должен быть массив лемм.\n",
    "Сравните лемматизацию с предложенной mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Незнакомые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('я',\n",
       "  OpencorporaTag('NPRO,1per sing,nomn'),\n",
       "  ((<DictionaryAnalyzer>, 'я', 3100, 0),)),\n",
       " ('пофиксила',\n",
       "  OpencorporaTag('NOUN,inan,femn plur,gent'),\n",
       "  ((<DictionaryAnalyzer>, 'сил', 55, 8), (<UnknownPrefixAnalyzer>, 'пофик'))),\n",
       " ('баг',\n",
       "  OpencorporaTag('NOUN,inan,masc sing,accs'),\n",
       "  ((<DictionaryAnalyzer>, 'баг', 19, 3),)),\n",
       " ('в', OpencorporaTag('PREP'), ((<DictionaryAnalyzer>, 'в', 375, 0),)),\n",
       " ('продакшен',\n",
       "  OpencorporaTag('NOUN,inan,masc,Geox sing,loct'),\n",
       "  ((<FakeDictionary>, 'продакшене', 32, 5), (<KnownSuffixAnalyzer>, 'шене'))),\n",
       " ('.', OpencorporaTag('PNCT'), ((<PunctuationAnalyzer>, '.'),))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = []\n",
    "for token in word_tokenize(unkn_sent):\n",
    "    ana = pymorphy2_analyzer.parse(token)[0]\n",
    "    lemmata.append((ana.normal_form, ana.tag, ana.methods_stack))\n",
    "lemmata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Склонение слов и согласование слов с числительными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inflection: территорию\n",
      "locative + 1: территории\n",
      "locative + 3: территориях\n",
      "locative + 5: территориях\n",
      "nominative + 1: территория\n",
      "nominative + 3: территории\n",
      "nominative + 5: территорий\n"
     ]
    }
   ],
   "source": [
    "loc_terra = terra[0]\n",
    "print('inflection:', loc_terra.inflect({'accs'}).word)\n",
    "print('locative + 1:', loc_terra.make_agree_with_number(1).word)\n",
    "print('locative + 3:', loc_terra.make_agree_with_number(3).word)\n",
    "print('locative + 5:', loc_terra.make_agree_with_number(5).word)\n",
    "\n",
    "nom_terra = loc_terra.inflect({'nomn'})\n",
    "print('nominative + 1:',nom_terra.make_agree_with_number(1).word)\n",
    "print('nominative + 3:',nom_terra.make_agree_with_number(3).word)\n",
    "print('nominative + 5:',nom_terra.make_agree_with_number(5).word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Снятие омонимии\n",
    "mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'сорока', 'analysis': [{'gr': 'NUM=(пр|дат|род|твор)', 'lex': 'сорок'}]}\n",
      "{'text': 'Сорока', 'analysis': [{'gr': 'S,жен,од=им,ед', 'lex': 'сорока'}]}\n"
     ]
    }
   ],
   "source": [
    "mystem_analyzer = Mystem() # инициализирую объект снова, потому что было задание на разные параметры, я хочу дефолтные\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Parse(word='сорока', tag=OpencorporaTag('NUMR loct'), normal_form='сорок', score=0.285714, methods_stack=((<DictionaryAnalyzer>, 'сорока', 2802, 5),))\n"
     ]
    }
   ],
   "source": [
    "ana1 = pymorphy2_analyzer.parse(homonym1.split(' ')[-2])\n",
    "ana2 = pymorphy2_analyzer.parse(homonym2.split(' ')[0])\n",
    "print(ana1 == ana2)\n",
    "print(ana1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стоп-слова\n",
    "Списки стоп-слов для русского есть разные, можно погуглить, а можно взять из nltk. Может быть, вы посчитаете нужным что-то в него добавить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Знаки препинания\n",
    "Списки знаков препинания тоже уже есть в питоне. Но этот список тоже может понадобиться пополнить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "## Задание 1.\n",
    "Напишите функцию, предобрабатывающую текст. Она вам пригодится для проекта. В предобработку входит:\n",
    "* токенизация\n",
    "* лемматизация (при которой произойдет lowercase)\n",
    "* удаление знаков препинания и стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    \"\"\"\n",
    "    Processes input text for further use in search engine.\n",
    "    :param text: str: input text.\n",
    "    :return: list[str]: lemmata list\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "Это часть вашего проекта.\n",
    "\n",
    "Прочитайте корпус, предобработайте каждый документ и сделайте (и сохраните в формате json) обратный индекс. Обратный индекс - словарь, где для каждого слова из корпуса есть список документов, в которых оно есть. Также подумайте, какую информацию по корпусу вам нужно сохранить (вспомните, что нужно для подсчета Okapi BM25) и сохраните ее тоже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
